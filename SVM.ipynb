{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l_VZ24MDXqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# final code for svm model\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "#################################\n",
        "\n",
        "import os,sys\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "import re\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "#creating dictionary of label file\n",
        "def create_train_dict(file_type):\n",
        "    file_link='https://drive.google.com/open?id=1JaN_rOB059Vq9Ya3x1U4AXm47lYLn8FG'\n",
        "    ## https://drive.google.com/open?id=1nQLJ-y-8XyEVQXYkR_o6HR_mnocHLsVJ   problem is there are different ids for each csv file\n",
        "    # https://drive.google.com/open?id=10m8b9cX_p-oDJMwZph2oykrjZCX31F-i\n",
        "    fluff, id = file_link.split('=')\n",
        "    #print (id)\n",
        "    downloaded = drive.CreateFile({'id':id}) \n",
        "    downloaded.GetContentFile('Filename.csv')  \n",
        "    df3 = pd.read_csv('Filename.csv')\n",
        "    train_dict={}\n",
        "    list_labels=[]\n",
        "    for line in df3:\n",
        "        datafile=df3['Datafile']\n",
        "        #print (datafile)\n",
        "        label=df3['Label'] # file label           \n",
        "        key=str(datafile)           #name of file\n",
        "        train_dict[key]=label\n",
        "        #print (train_dict[key])\n",
        "        #list_labels.append(train_dict[key])\n",
        "    #return (train_dict,list_labels)\n",
        "    return (train_dict)\n",
        "    \n",
        "\n",
        "#printing dictionary of train.csv\n",
        "def get_path(keys):\n",
        "    #path = 'E:/DE/Sem2/AdvancedProject/bbdc_2019_Bewegungsdaten/'+ keys\n",
        "    print (keys)\n",
        "    if(keys.find(\"Subject02\")!=-1):\n",
        "      print (\"yes\")\n",
        "      f2_link='https://drive.google.com/open?id=1r80_evl0MX34_AC7IB4v13MVps-MBEkV'\n",
        "      fluff, id02 = f2_link.split('=')\n",
        "      #print (id)\n",
        "      downloaded = drive.CreateFile({'id':id02}) \n",
        "      #path=downloaded.GetContentFile('s2'+keys+'.csv')\n",
        "      path=downloaded.GetContentFile(keys)\n",
        "      print (path)\n",
        "      return (path)\n",
        "\n",
        "def label_conversion_to_numericals(train_labels):\n",
        "    encoder = preprocessing.LabelEncoder()\n",
        "    encoder.fit(train_labels)\n",
        "    activity_labels_nums = encoder.transform(train_labels)\n",
        "    return activity_labels_nums\n",
        "\n",
        "def main(i):\n",
        "    flag=0          # flag for creating array of labels\n",
        "    y_label=[]\n",
        "    train_labels=[]\n",
        "    #y_label=np.zeros(412740)\n",
        "    #train_dict,train_labels=create_train_dict(i)\n",
        "    train_dict=create_train_dict(i)\n",
        "    for keys in train_dict:\n",
        "      label=train_dict[keys]\n",
        "      train_labels.append(label)\n",
        "    train_labels_arr=np.array(train_labels)\n",
        "    train_labels_arr=train_labels_arr.reshape(165,1)\n",
        "    #print (train_labels_arr.shape)\n",
        "    #print (train_labels_arr)\n",
        "    X_train_all=np.empty((0,19))\n",
        "    X_test_all=np.empty((0,19))\n",
        "    \n",
        "# converting string labels from train.csv to integers\n",
        "    if (i=='dummy_train2.csv'):\n",
        "        labels_nums=label_conversion_to_numericals(train_labels_arr)\n",
        "#        print (labels_nums) #array\n",
        "        \n",
        "    for keys in train_dict:       # keys = file name\n",
        "        #print (keys)\n",
        "        path=get_path(keys)\n",
        "        print (path)\n",
        "        f=pd.read_csv(r''+path)    # reading file\n",
        "        dim=f.shape               # dim of file\n",
        "        scaler = StandardScaler() # feature scaling\n",
        "        if(re.match('Subject01|Subject14|Subject15',keys)==None):\n",
        "            for i in range(0,dim[0]):\n",
        "                y_label.append(labels_nums[flag])\n",
        "                #print(labels_nums[flag])\n",
        "            flag+=1\n",
        "        #    print (flag)\n",
        "            #print (y_label[6200])\n",
        "            X_train_scaled= scaler.fit_transform(f)\n",
        "            X_train_all=np.concatenate((X_train_all,X_train_scaled),axis=0)\n",
        "        else:\n",
        "            X_test_scaled = scaler.fit_transform(f)\n",
        "            X_test_all=np.concatenate((X_test_all,X_test_scaled),axis=0)\n",
        "    print(shape(y_label))\n",
        "    #print (\"after al concatenation\",X_train_all.shape)\n",
        "    # arrays formed on splitting \n",
        "    #print(\"x-train\",X_train_all.shape,\"y train\", y_label.shape)\n",
        "    X_train, X_test, y_train, y_test= train_test_split(X_train_all, y_label, test_size=0.3, random_state=0)  # 70% training\n",
        "    num_labels=len(y_train)\n",
        "    #print (num_labels)\n",
        "    params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [1, 10, 100, 1000]}\n",
        "    #{'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]    \n",
        "    svm_model = GridSearchCV(SVC(), params_grid, cv=5)\n",
        "    svm_model.fit(X_train, y_train)\n",
        "    #print('Best score for training data:', svm_model.best_score_,\"\\n\") \n",
        "\n",
        "\n",
        "file=['train.csv','test.csv'] #,'dummy_test2.csv'\n",
        "for i in (file):\n",
        "    main(i)\n",
        "    \n",
        "# Predicting the Test set results\n",
        "y_pred = svm_model.predict(X_test)\n",
        "#Reverse factorize (converting y_pred from numbers to names\n",
        "reversefactor = dict(zip(range(23),definitions))\n",
        "y_test = np.vectorize(reversefactor.get)(y_test)\n",
        "y_pred = np.vectorize(reversefactor.get)(y_pred)\n",
        "# Making the Confusion Matrix\n",
        "print(pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted']))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHltR5JZDXrz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "file=pd.read_csv('Subject_02_Aufnahme000.csv',encoding='utf-8')    # reading file\n",
        "for line in file:\n",
        "    print (line)\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ENjgTX6DXsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "b = np.array([3,4,7])\n",
        "c = np.setdiff1d(a,b)\n",
        "print (c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBsbJQjQDXsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "X_train=open('E:/DE/Sem2/DataMining/Diogo/data_X_train.file','r')\n",
        "print (X_train.read)\n",
        "Y_train=open('E:/DE/Sem2/DataMining/Diogo/data_y_train.file','r')\n",
        "params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [1, 10, 100, 1000]},{'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
        "svm_model = GridSearchCV(SVC(), params_grid, cv=5)\n",
        "svm_model.fit(X_train, Y_train)\n",
        "print('Best score for training data:', svm_model.best_score_,\"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5wEUlUiDXse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# forming y_train based on number of examples\n",
        "def dup(dim,flag):\n",
        "    fl=flag\n",
        "    labels_nums=[2,3,4]\n",
        "    for i in range(0,dim[0]):\n",
        "        print (labels_nums[fl])\n",
        "        y_label.append(labels_nums[fl])\n",
        "    fl+=1\n",
        "    return (fl,y_label)\n",
        "\n",
        "def main():\n",
        "    flag=0\n",
        "    dim_list=[[10,2],[5,4]]\n",
        "    y_label=[]\n",
        "    for i in range(len(dim_list)):\n",
        "        flag,y_label=dup(dim_list[i],flag)\n",
        "        print (\"flag\",flag)\n",
        "        print (y_label)\n",
        "\n",
        "        \n",
        "\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-BWfjJ8DXsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st='Subject02_Aufnahme000.csv'\n",
        "if(re.match('02',st)!=None):\n",
        "  print (\"ya\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}